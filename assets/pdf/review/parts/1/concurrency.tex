\chapterimage{chapter_head_2.pdf}

\chapter{Concurrency}

\section{Concurrency Defense Principles}\index{Concurrency!Concurrency Defense Principles}

While reviewing code, here are series of principles that the code under review should  follow in order to defend a system from the problem of concurrent code.

\subsection{Single Responsibility Principle}

In order for concurrency-related code to obey SRP, here are a few things to consider:

\begin{itemize}
    \item Concurrency-related code has its own life cycle of development, change, and tuning.
    \item Concurrency-related code has its own challenges, which are different from and often more difficult than nonconcurrency-related code.
    \item The number of ways in which miswritten concurrency-based code can fail makes it challenging enough without the added burden of surrounding application code.
\end{itemize}

\begin{marker}
Keep your concurrency-related code separate from other code
\end{marker}

\subsection{Limit the Scope of Data}

As we saw, two threads modifying the same field of a shared object can interfere with each other, causing unexpected behavior. One solution is to use the synchronized keyword to protect a critical section in the code that uses the shared object. It is important to restrict the number of such critical sections. The more places shared data can get updated, the more likely:

\begin{itemize}
    \item You will forget to protect one or more of those placesâ€”effectively breaking all code that modifies that shared data.
    \item There will be duplication of effort required to make sure everything is effectively guarded (violation of DRY).
    \item It will be difficult to determine the source of failures.
\end{itemize}

\begin{marker}
Take data encapsulation to heart; severely limit the access of any data that may be shared.
\end{marker}

\subsection{Use Copies of Data}

A good way to avoid shared data is to avoid sharing the data in the first place. In some situations it is possible to copy objects and treat them as read-only. In other cases it might be possible to copy objects, collect results from multiple threads in these copies and then merge the results in a single thread.

If there is an easy way to avoid sharing objects, the resulting code will be far less likely to cause problems. You might be concerned about the cost of all the extra object creation. It is worth experimenting to find out if this is in fact a problem. However, if using copies of objects allows the code to avoid synchronizing, the savings in avoiding the intrinsic lock will likely make up for the additional creation and garbage collection overhead.

\begin{marker}
Try make it possible to have each thread manipulate just "copies" of data
\end{marker}

\subsection{Threads Should Be as Independent as Possible}

Consider writing your threaded code such that each thread exists in its own world, sharing no data with any other thread. Each thread processes one client request, with all of its required data coming from an unshared source and stored as local variables. This makes each of those threads behave as if it were the only thread in the world and there were no synchronization requirements.

\begin{marker}
Attempt to partition data into independent subsets than can be operated on by independent threads, possibly in different processors.
\end{marker}

\section{Know Library}\index{Concurrency!Know Library}

Inexperience developer are not aware of all concurrency libraries in Java; it is reviewer's responsibility to let them know and they should also study it. For example, if you see a class with a \inlinecode[blue]{HashMap} plus a \inlinecode[blue]{Lock}, you should tell them to use \inlinecode[green]{ConcurrentHashMap} instead.

\begin{marker}
Ask people working on concurrency code to review the classes available to them such as \inlinecode[green]{java.util.concurrent}, \inlinecode[green]{java.util.concurrent.atomic}, and \inlinecode[green]{java.util.concurrent.locks}.
\end{marker}

\section{Review for Execution Models}\index{Concurrency!Review for Execution Models}

We you are reviewing concurrency-related code, your first task is to identify the execution model that's being used for implementation:

\begin{itemize}
    \item \textbf{Producer-Consumer} One or more producer threads create some work and place it in a buffer or queue. One or more consumer threads acquire that work from the queue and complete it. The queue between the producers and consumers is a \textit{bound resource} (Resources of a fixed size or number used in a concurrent environment. Examples include database connections and fixed-size read/write buffers.). This means producers must wait for free space in the queue before writing and consumers must wait until there is something in the queue to consume. Coordination between the producers and consumers via the queue involves producers and consumers signaling each other. The producers write to the queue and signal that the queue is no longer empty. Consumers read from the queue and signal that the queue is no longer full. Both potentially wait to be notified when they can continue.
    \item \textbf{Readers-Writers} When you have a shared resource that primarily serves as a source of information for readers, but which is occasionally updated by writers, throughput is an issue. Emphasizing throughput can cause starvation and the accumulation of stale information. Allowing updates can impact throughput. Coordinating readers so they do not read something a writer is updating and vice versa is a tough balancing act. Writers tend to block many readers for a long period of time, thus causing throughput issues. The challenge is to balance the needs of both readers and writers to satisfy correct operation, provide reasonable throughput and avoiding starvation. A simple strategy makes writers wait until there are no readers before allowing the writer to perform an update. If there are continuous readers, however, the writers will be starved. On the other hand, if there are frequent writers and they are given priority, throughput will suffer. Finding that balance and avoiding concurrent update issues is what the problem addresses.
    \item \textbf{Dining Philosophers} Imagine a number of philosophers sitting around a circular table. A fork is placed to the left of each philosopher. There is a big bowl of spaghetti in the center of the table. The philosophers spend their time thinking unless they get hungry. Once hungry, they pick up the forks on either side of them and eat. A philosopher cannot eat unless he is holding two forks. If the philosopher to his right or left is already using one of the forks he needs, he must wait until that philosopher finishes eating and puts the forks back down. Once a philosopher eats, he puts both his forks back down on the table and waits until he is hungry again. Replace philosophers with threads and forks with resources and this problem is similar to many enterprise applications in which processes compete for resources. Unless carefully designed, systems that compete in this way can experience deadlock, livelock, throughput, and efficiency degradation.
\end{itemize}

Most concurrent problems you will likely encounter will be some variation of these three problems. Study these algorithms and solutions of them on your own so
that when you come across code addressing concurrent problems, you'll be more prepared to review them.

\begin{marker}
Learn these basic algorithms and understand their solutions.
\end{marker}

\section{Keep Synchronized Sections Small}\index{Concurrency!Keep Synchronized Sections Small}

The \inlinecode[green]{synchronized} keyword introduces a lock. All sections of code guarded by the same lock are guaranteed to have only one thread executing through them at any given time. Locks are expensive because they create delays and add overhead. So we don't want to litter our code with \inlinecode[green]{synchronized} statements. On the other hand, critical sections must be guarded. So we want to design our code with as few critical sections as possible. Some naive programmers try to achieve this by making their critical sections very large. However, extending synchronization beyond the minimal critical section increases contention and degrades performance.

\begin{marker}
Keep synchronized sections as small as possible.
\end{marker}
