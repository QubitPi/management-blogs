---
layout: post
title: Graph Analytics & Machine Learning through ArangoDB
tags: [ArangoDB, Database, Knowledge Graph, Machine Learning]
category: WIP
color: rgb(128, 165, 76)
feature-img: "assets/img/post-cover/9-cover.png"
thumbnail: "assets/img/post-cover/9-cover.png"
author: QubitPi
excerpt_separator: <!--more-->
---

ArangoDB lets you apply analytics and machine learning to graph data at scale

<!--more-->

ArangoDB's Graph Analytics and GraphML capabilities provide various solutions in data science and data analytics.
Multiple data science personas within the engineering space can make use of ArangoDB's set of tools and technologies
that enable analytics and machine learning on graph data.

ArangoDB, as the foundation for GraphML, comes with the following key features:

* **Scalable**: designed to support true scalability with high performance for enterprise use cases.
* **Simple Ingestion**: easy integration in existing data infrastructure with connectors to all leading data processing
  and data ecosystems.
* **Open Source**: extensibility and community.
* **NLP Support**: built-in text processing, search, and similarity ranking.

![Error loading arango-machine-learning-architecture.png!]({{ "/assets/img/arango-machine-learning-architecture.png" | relative_url}})

* TOC
{:toc}


Graph Query v.s. Graph Analytics v.s Graph Machine Learning (GraphML)
---------------------------------------------------------------------

### Graph Query

When running a query with AQL on a graph, the query goes from a vertex to an edge, and then the edge indicates what the 
next connected vertex will be. Graph queries can answer questions like _Who can introduce me to person X?_

![Error loading arango-graph-query.png!]({{ "/assets/img/arango-graph-query.png" | relative_url}})

### Graph Analytics

Graph analytics or graph algorithms is what you run on a graph if you want to know aggregate information about your
graph, while analyzing the entire graph. Graph analytics can answer questions like _Who are the most connected persons?_

![Error arango-graph-analytics.png!]({{ "/assets/img/arango-graph-analytics.png" | relative_url}})

Graph Analytics is applicable in various fields such as marketing, fraud detection, supply chain, product
recommendations, drug development, law enforcement, and cybersecurity. It uses an unsupervised learning method that 
performs analytical processing directly on graphs stored in ArangoDB. The
[Distributed Iterative Graph Processing (Pregel)](#distributed-iterative-graph-processing-pregel) is intended to help
you gain analytical insights in your data, without having to use external processing systems.

ArangoDB includes the following graph algorithms:

* [Page Rank](#pagerank): used for ranking documents in a graph search/traversal.
* [Single-Source Shortest Path](#single-source-shortest-path): calculates the shortest path length between the source
  and all other vertices. For example, _How to get from a to b?_
* [Hyperlink-Induced Topic Search (HITS)](#hyperlink-induced-topic-search-hits): a link analysis algorithm that rates
  web pages.
* [Vertex Centrality](#vertex-centrality): identifies the most important nodes in a graph. For example,
  _Who are the influencers in a social network?_
* [Community Detection](#community-detection): identifies distinct subgroups within a community structure.

### GraphML

When applying machine learning on a graph, you can predict connections, get better product recommendations, and also 
classify vertices, edges, and graphs. GraphML can answer questions like:

* _Is there a connection between person X and person Y?_
* _Will a customer churn?_
* _Is this particular transaction Anomalous?_

![Error arango-graph-ml.png!]({{ "/assets/img/arango-graph-ml.png" | relative_url}})

GraphML capabilities of using more data outperform conventional deep learning methods and solve high-computational 
complexity graph problems, such as:

* Drug discovery, repurposing, and predicting adverse effects.
* Personalized product/service recommendation.
* Supply chain and logistics.

With GraphML, you can also predict relationships and structures, such as:

* Predict molecules for treating diseases (precision medicine).
* Predict fraudulent behavior, credit risk, purchase of product or services.
* Predict relationships among customers, accounts.

ArangoDB uses well-known GraphML frameworks like [Deep Graph Library](https://www.dgl.ai/) and
[PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) and connects to these external machine learning 
libraries. When coupled to ArangoDB, you are essentially integrating them with your graph dataset.

Distributed Iterative Graph Processing (Pregel)
-----------------------------------------------

Pregel enables you to do online analytical processing directly on graphs stored in ArangoDB.

Distributed graph processing enables you to do online analytical processing directly on graphs stored in ArangoDB. This
is intended to help you gain analytical insights on your data, without having to use external processing systems.
Examples of algorithms to execute include

* [PageRank](#pagerank)
* [Vertex Centrality](#vertex-centrality)
* Vertex Closeness
* [Connected Components](#connected-components)
* [Community Detection](#community-detection)

The processing system inside ArangoDB is based on
[_Pregel: A System for Large-Scale Graph Processing_]({{ "/assets/pdf/pregel.pdf" | relative_url}}) - Malewicz et al. 
(Google), 2010. This concept enables us to perform distributed graph processing, without the need for distributed global 
locking.

This system is not useful for typical online queries, where you just work on a small set of vertices. These kind of tasks are better suited for
[AQL traversals](https://qubitpi.github.io/jersey-guide/finalized/2022/09/02/arango-aql.html#graph).

### Pregel Community Detection Tutorial

> 📋 This tutorial is tailored to Mac OS X. 

Community structures are quite common in real networks. For example, social networks include community groups (the
origin of the term, in fact) based on common locations, hobbies, occupation, etc. Finding an underlying community
structure in a network, if it exists, is important for a number of reasons. Communities allow us to create a large scale 
map of a network since individual communities act like meta-nodes in the network which makes its study easier.

#### Creating the ArangoDB Graph

The data we are going to use is the Pokec social network available from the
[Stanford Network Analysis Project](http://snap.stanford.edu/data/soc-pokec.html). Pokec is the most popular on-line 
social network in Slovakia, we will use it to detect communities in the graph. We assume that as a social network it 
contains an underlying community structure, which we can discover through one of our algorithms.

As a first step, you should install and start the ArangoDB cluster. 

Next we will [log into Arango shell](https://github.com/arangodb/arangodb/issues/12435#issuecomment-704856496):

{% highlight bash %}
$ /Applications/ArangoDB3-CLI.app/Contents/Resources/arangosh
Please specify a password:
{% endhighlight %}

Simply hit "Enter" and you will be logged in as root:

{% highlight bash %}
$ /Applications/ArangoDB3-CLI.app/Contents/Resources/arangosh
Please specify a password:

                                       _     
__ _ _ __ __ _ _ __   __ _  ___  ___| |__  
/ _` | '__/ _` | '_ \ / _` |/ _ \/ __| '_ \
| (_| | | | (_| | | | | (_| | (_) \__ \ | | |
\__,_|_|  \__,_|_| |_|\__, |\___/|___/_| |_|
|___/

arangosh (ArangoDB 3.7.11 [darwin] 64bit, using build tags/v3.7.11-0-g5ca39c161b, VPack 0.1.33, RocksDB 6.8.0, ICU 64.2, V8 7.9.317, OpenSSL 1.1.1k  25 Mar 2021)
Copyright (c) ArangoDB GmbH

Command-line history will be persisted when the shell is exited. You can use `--console.history false` to turn this off
Connected to ArangoDB 'http+tcp://127.0.0.1:8529, version: 3.7.11 [SINGLE, server], database: '_system', username: 'root'

Type 'tutorial' for a tutorial or 'help' to see common examples
127.0.0.1:8529@_system>
{% endhighlight %}

{% highlight javascript %}
arangosh> require("@arangodb").db._name();
_system
{% endhighlight %}

The next step is to create the collections and the arangodb named "graph". In the arangosh prompt you can paste in the 
following commands:

{% highlight javascript %}
var graph_module = require("@arangodb/general-graph");

var graph = graph_module._create("pokec");
db._create("profiles", {numberOfShards: 4});

graph._addVertexCollection("profiles");
db._createEdgeCollection("relations", {

numberOfShards: 4,
replicationFactor: 1,
shardKeys:["vertex"],
distributeShardsLike:"profiles"});

var rel = graph_module._relation("relations", ["profiles"], ["profiles"]);

graph._extendEdgeDefinitions(rel);
{% endhighlight %}

#### Preparing and importing the graph data

You can run these bash commands to directly download the data

{% highlight bash %}
curl -OL https://snap.stanford.edu/data/soc-pokec-profiles.txt.gz
curl -OL https://snap.stanford.edu/data/soc-pokec-relationships.txt.gz
{% endhighlight %}

Now we can extract both files and transform them into a format which can be imported by ArangoDBs community edition. Our 
goal is it to get tab separated CSV files

First, we create a csv file containing all user profiles, by running these bash commands:

{% highlight bash %}
echo -e '_key\tpublic\tcompletion_percentage\tgender\tregion\tlast_login\tregistration\tAGE\tbody\tI_am_working_in_field\tspoken_languages\thobbies\tI_most_enjoy_good_food\tpets\tbody_type\tmy_eyesight\teye_color\thair_color\thair_type\tcompleted_level_of_education\tfavourite_color\trelation_to_smoking\trelation_to_alcohol\tsign_in_zodiac\ton_pokec_i_am_looking_for\tlove_is_for_me\trelation_to_casual_sex\tmy_partner_should_be\tmarital_status\tchildren\trelation_to_children\tI_like_movies\tI_like_watching_movie\tI_like_music\tI_mostly_like_listening_to_music\tthe_idea_of_good_evening\tI_like_specialties_from_kitchen\tfun\tI_am_going_to_concerts\tmy_active_sports\tmy_passive_sports\tprofession\tI_like_books\tlife_style\tmusic\tcars\tpolitics\trelationships\tart_culture\thobbies_interests\tscience_technologies\tcomputers_internet\teducation\tsport\tmovies\ttravelling\thealth\tcompanies_brands\tmore\tmore_2' > soc-pokec-profiles-arangodb.txt

gunzip < soc-pokec-profiles.txt.gz | sed -e 's/null//g' -e 's~^~P~' -e 's~ $~~' >> soc-pokec-profiles-arangodb.txt
{% endhighlight %}

Next we take the relations file and do the same thing. Maybe go and get a coffee now, this might take a few minutes.

{% highlight bash %}
echo -e '_from\t_to\tvertex' > soc-pokec-relationships-arangodb.txt

gzip -dc soc-pokec-relationships.txt.gz | awk -F"\t" '{print "profiles/P" $1 "\tprofiles/P" $2 "\tP" $1}' >> soc-pokec-relationships-arangodb.txt
{% endhighlight %}


Now that we have the data ready for import we can import into our arangodb instance. Adjust the
`--server.endpoint` option as necessary

{% highlight bash %}
$ /Applications/ArangoDB3-CLI.app/Contents/Resources/arangoimp -c none --server.endpoint http+tcp://127.0.0.1:8529 --type tsv --collection profiles --file soc-pokec-profiles-arangodb.txt
Please specify a password:
Connected to ArangoDB 'http+tcp://127.0.0.1:8529, version: 3.7.11, database: '_system', username: 'root'
----------------------------------------
database:               _system
collection:             profiles
create:                 no
create database:        no
source filename:        soc-pokec-profiles-arangodb.txt
file type:              tsv
separator:              
threads:                2
connect timeout:        5
request timeout:        1200
----------------------------------------
Starting TSV import...
2022-09-03T05:43:59Z [88108] INFO [9ddf3] processed 47939584 bytes (3%) of input file
2022-09-03T05:43:59Z [88108] INFO [9ddf3] processed 95846400 bytes (6%) of input file
2022-09-03T05:44:00Z [88108] INFO [9ddf3] processed 143785984 bytes (9%) of input file
2022-09-03T05:44:00Z [88108] INFO [9ddf3] processed 191692800 bytes (12%) of input file
2022-09-03T05:44:01Z [88108] INFO [9ddf3] processed 239599616 bytes (15%) of input file
2022-09-03T05:44:01Z [88108] INFO [9ddf3] processed 287539200 bytes (18%) of input file
2022-09-03T05:44:02Z [88108] INFO [9ddf3] processed 335446016 bytes (21%) of input file
2022-09-03T05:44:02Z [88108] INFO [9ddf3] processed 383352832 bytes (24%) of input file
2022-09-03T05:44:03Z [88108] INFO [9ddf3] processed 431292416 bytes (27%) of input file
2022-09-03T05:44:03Z [88108] INFO [9ddf3] processed 479199232 bytes (30%) of input file
2022-09-03T05:44:04Z [88108] INFO [9ddf3] processed 527138816 bytes (33%) of input file
2022-09-03T05:44:04Z [88108] INFO [9ddf3] processed 575045632 bytes (36%) of input file
2022-09-03T05:44:05Z [88108] INFO [9ddf3] processed 622952448 bytes (39%) of input file
2022-09-03T05:44:06Z [88108] INFO [9ddf3] processed 670892032 bytes (42%) of input file
2022-09-03T05:44:06Z [88108] INFO [9ddf3] processed 718798848 bytes (45%) of input file
2022-09-03T05:44:07Z [88108] INFO [9ddf3] processed 766705664 bytes (48%) of input file
2022-09-03T05:44:07Z [88108] INFO [9ddf3] processed 814645248 bytes (51%) of input file
2022-09-03T05:44:08Z [88108] INFO [9ddf3] processed 862552064 bytes (54%) of input file
2022-09-03T05:44:09Z [88108] INFO [9ddf3] processed 910491648 bytes (57%) of input file
2022-09-03T05:44:10Z [88108] INFO [9ddf3] processed 958398464 bytes (60%) of input file
2022-09-03T05:44:10Z [88108] INFO [9ddf3] processed 1006305280 bytes (63%) of input file
2022-09-03T05:44:11Z [88108] INFO [9ddf3] processed 1054244864 bytes (66%) of input file
2022-09-03T05:44:12Z [88108] INFO [9ddf3] processed 1102151680 bytes (69%) of input file
2022-09-03T05:44:13Z [88108] INFO [9ddf3] processed 1150058496 bytes (72%) of input file
2022-09-03T05:44:14Z [88108] INFO [9ddf3] processed 1197998080 bytes (75%) of input file
2022-09-03T05:44:15Z [88108] INFO [9ddf3] processed 1245904896 bytes (78%) of input file
2022-09-03T05:44:16Z [88108] INFO [9ddf3] processed 1293844480 bytes (81%) of input file
2022-09-03T05:44:17Z [88108] INFO [9ddf3] processed 1341751296 bytes (84%) of input file
2022-09-03T05:44:18Z [88108] INFO [9ddf3] processed 1389658112 bytes (87%) of input file
2022-09-03T05:44:19Z [88108] INFO [9ddf3] processed 1437597696 bytes (90%) of input file
2022-09-03T05:44:21Z [88108] INFO [9ddf3] processed 1485504512 bytes (93%) of input file
2022-09-03T05:44:22Z [88108] INFO [9ddf3] processed 1533411328 bytes (96%) of input file
2022-09-03T05:44:24Z [88108] INFO [9ddf3] processed 1581350912 bytes (99%) of input file

created:          1632803
warnings/errors:  0
updated/replaced: 0
ignored:          0
lines read:       1632805
{% endhighlight %}

![Error arango-pokec-profiles-loaded.png!]({{ "/assets/img/arango-pokec-profiles-loaded.png" | relative_url}})

{% highlight bash %}
$ /Applications/ArangoDB3-CLI.app/Contents/Resources/arangoimp -c none --server.endpoint http+tcp://127.0.0.1:8529  --type tsv --collection relations --file soc-pokec-relationships-arangodb.txt
Please specify a password:
Connected to ArangoDB 'http+tcp://127.0.0.1:8529, version: 3.7.11, database: '_system', username: 'root'
----------------------------------------
database:               _system
collection:             relations
create:                 no
create database:        no
source filename:        soc-pokec-relationships-arangodb.txt
file type:              tsv
separator:              
threads:                2
connect timeout:        5
request timeout:        1200
----------------------------------------
Starting TSV import...
2022-09-03T05:07:36Z [85838] INFO [9ddf3] processed 38404096 bytes (3%) of input file
2022-09-03T05:07:59Z [85838] INFO [9ddf3] processed 76775424 bytes (6%) of input file
2022-09-03T05:08:20Z [85838] INFO [9ddf3] processed 115146752 bytes (9%) of input file
2022-09-03T05:08:36Z [85838] INFO [9ddf3] processed 153518080 bytes (12%) of input file
2022-09-03T05:08:59Z [85838] INFO [9ddf3] processed 191889408 bytes (15%) of input file
2022-09-03T05:09:21Z [85838] INFO [9ddf3] processed 230260736 bytes (18%) of input file
2022-09-03T05:09:44Z [85838] INFO [9ddf3] processed 268632064 bytes (21%) of input file
2022-09-03T05:10:02Z [85838] INFO [9ddf3] processed 307003392 bytes (24%) of input file
2022-09-03T05:10:27Z [85838] INFO [9ddf3] processed 345374720 bytes (27%) of input file
2022-09-03T05:10:50Z [85838] INFO [9ddf3] processed 383746048 bytes (30%) of input file
2022-09-03T05:11:10Z [85838] INFO [9ddf3] processed 422117376 bytes (33%) of input file
2022-09-03T05:11:31Z [85838] INFO [9ddf3] processed 460488704 bytes (36%) of input file
2022-09-03T05:11:51Z [85838] INFO [9ddf3] processed 498860032 bytes (39%) of input file
2022-09-03T05:12:07Z [85838] INFO [9ddf3] processed 537231360 bytes (42%) of input file
2022-09-03T05:12:29Z [85838] INFO [9ddf3] processed 575602688 bytes (45%) of input file
2022-09-03T05:12:50Z [85838] INFO [9ddf3] processed 613974016 bytes (48%) of input file
2022-09-03T05:13:07Z [85838] INFO [9ddf3] processed 652345344 bytes (51%) of input file
2022-09-03T05:13:28Z [85838] INFO [9ddf3] processed 690716672 bytes (54%) of input file
2022-09-03T05:13:44Z [85838] INFO [9ddf3] processed 729088000 bytes (57%) of input file
2022-09-03T05:14:05Z [85838] INFO [9ddf3] processed 767459328 bytes (60%) of input file
2022-09-03T05:14:28Z [85838] INFO [9ddf3] processed 805830656 bytes (63%) of input file
2022-09-03T05:14:49Z [85838] INFO [9ddf3] processed 844201984 bytes (66%) of input file
2022-09-03T05:15:11Z [85838] INFO [9ddf3] processed 882573312 bytes (69%) of input file
2022-09-03T05:15:34Z [85838] INFO [9ddf3] processed 920944640 bytes (72%) of input file
2022-09-03T05:15:51Z [85838] INFO [9ddf3] processed 959315968 bytes (75%) of input file
2022-09-03T05:16:12Z [85838] INFO [9ddf3] processed 997687296 bytes (78%) of input file
2022-09-03T05:16:34Z [85838] INFO [9ddf3] processed 1036058624 bytes (81%) of input file
2022-09-03T05:16:55Z [85838] INFO [9ddf3] processed 1074429952 bytes (84%) of input file
2022-09-03T05:17:16Z [85838] INFO [9ddf3] processed 1112801280 bytes (87%) of input file
2022-09-03T05:17:37Z [85838] INFO [9ddf3] processed 1151172608 bytes (90%) of input file
2022-09-03T05:17:52Z [85838] INFO [9ddf3] processed 1189543936 bytes (93%) of input file
2022-09-03T05:18:12Z [85838] INFO [9ddf3] processed 1227915264 bytes (96%) of input file
2022-09-03T05:18:32Z [85838] INFO [9ddf3] processed 1266286592 bytes (99%) of input file

created:          30622564
warnings/errors:  0
updated/replaced: 0
ignored:          0
lines read:       30622566
{% endhighlight %}

We shall be able to see the relation data in Arango UI now: 

![Error arango-pokec-relation-loaded.png!]({{ "/assets/img/arango-pokec-relation-loaded.png" | relative_url}})

#### Running the Algorithms

Now that you have imported the data we can start working with it. We could try two community detection algorithms

1. [Label Propagation (LP)](https://en.wikipedia.org/wiki/Label_Propagation_Algorithm)
2. [Disassortative Degree Mixing and Information Diffusion (DMID)](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1057.7328&rep=rep1&type=pdf)

These algorithms have different purposes: LP can recognize distinct communities in a graph and is very cheap in terms of 
memory consumption.

On the other hand DMID is designed to detect overlapping communities. It does not assume a fixed number of communities
and can discover the communities on the fly.

Now in arangoshell execute the LP-algorithm:

{% highlight javascript %}
var pregel = require("@arangodb/pregel");

var handle = pregel.start("labelpropagation", "pokec", {maxGSS:250, resultField:"community"});

pregel.status(handle);
{% endhighlight %}

The Pregel API is accessible through `@arangodb/pregel` package.

To start an execution we need to specify the algorithm name and a named graph. Alternatively, we can specify the vertex 
and edge collections. Additionally, we shall specify custom parameters which vary for each algorithm. The `start()`
method always returns a unique ID (a number) that can be used to interact with the algorithm and later on.

> params needs to be an object, the valid keys are mentioned each of [available algorithms](#pregel-algorithms).

Alternatively, we might want to specify the vertex and edge collections directly. The call syntax of the `start()`
method changes in this case. The second argument must be an object with the keys `vertexCollections` and
`edgeCollections`.

{% highlight javascript %}
var pregel = require("@arangodb/pregel");
var params = {};
var execution = pregel.start("<algorithm>", {vertexCollections:["vertices"], edgeCollections:["edges"]}, params);
{% endhighlight %}

We shall check the status periodically for completion:

{% highlight javascript %}
127.0.0.1:8529@_system> pregel.status(handle);
{
    "state" : "running",
    "gss" : 0,
    "totalRuntime" : 0,
    "startupTime" : 0,
    "computationTime" : 0,
    "aggregators" : {
    },
    "sendCount" : 0,
    "receivedCount" : 0
}

...

127.0.0.1:8529@_system> pregel.status(handle);
{
    "state" : "running",
    "gss" : 23,
    "totalRuntime" : 0,
    "startupTime" : 62.607675075531006,
    "computationTime" : -62.607675075531006,
    "aggregators" : {
    },
    "sendCount" : 384543168,
    "receivedCount" : 369833590
}
{% endhighlight %}

At this moment we shall be able to visually examine the computation on interface UI:

![Error arango-pregel-intermediate.png!]({{ "/assets/img/arango-pregel-intermediate.png" | relative_url}})

When execution finishes, we should see the status changing to "storing" and, shortly after, to "done":

{% highlight javascript %}
127.0.0.1:8529@_system> pregel.status(handle);
{
    "state" : "storing",
    "gss" : 250,
    "totalRuntime" : 0,
    "startupTime" : 62.607675075531006,
    "computationTime" : 2362.1986091136932,
    "aggregators" : {
    },
    "sendCount" : 3584184192,
    "receivedCount" : 3575458417,
    "vertexCount" : 1632803,
    "edgeCount" : 30622564
}

127.0.0.1:8529@_system> pregel.status(handle);
{
    "state" : "done",
    "gss" : 250,
    "totalRuntime" : 2467.485207080841,
    "startupTime" : 62.607675075531006,
    "computationTime" : 2362.1986091136932,
    "storageTime" : 42.678926944732666,
    "aggregators" : {
    },
    "sendCount" : 3584184192,
    "receivedCount" : 3575458417,
    "vertexCount" : 1632803,
    "edgeCount" : 30622564
}
{% endhighlight %}

The resulting graph after execution completes successfully is the following:

![Error arango-pregel-finished.png!]({{ "/assets/img/arango-pregel-finished.png" | relative_url}})

The code returned by the `pregel.start(...)` method can be used to track the status of your algorithm.

{% highlight javascript %}
var execution = pregel.start("sssp", "demograph", {source: "vertices/V"});
var status = pregel.status(execution);
{% endhighlight %}

It tells you the current _state_ of the execution, the current global superstep, the runtime, the global aggregator
values as well as the number of send and received messages.

> The state field has one of the following values:
>
> | **State**    | **Description**                                                                                                                                                                                                                                                                |
> |--------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
> | "running"    | Algorithm is executing normally.                                                                                                                                                                                                                                               |
> | "in error"   | The execution is in an error state. This can be caused by primary DB-Servers being not reachable or being non responsive. The execution might recover later, or switch to “canceled” if it was not able to recover successfully                                                |
> | "recovering" | The execution is actively recovering, will switch back to “running” if the recovery was successful                                                                                                                                                                             |
> | "canceled"   | The execution was permanently canceled, either by the user or by an error.                                                                                                                                                                                                     |
> | "storing"    | The algorithm finished, but the results are still being written back into the collections. Occurs if the `store` parameter is set to `true` only.                                                                                                                              |
> | "done"       | The execution is done. In version 3.7.1 and later, this means that storing is also done. In earlier versions, the results may not be written back into the collections yet. This event is announced in the server log (requires at least info log level for the pregel topic). |

#### Canceling an Algorithm Execution

To cancel an execution which is still running, and discard any intermediate results you can use the `cancel()` method. 
This will immediately free all memory taken up by the execution, but will make you lose all intermediary data.

{% highlight javascript %}
// start a single source shortest path job
var execution = pregel.start("sssp", "demograph", {source: "vertices/V"});
pregel.cancel(execution);
{% endhighlight %}

You might get inconsistent results if you requested to store the results and then cancel an execution when it is already 
in its storing state. The data is written multi-threaded into all collection shards at once. This means there are
multiple transactions simultaneously. A transaction might already be committed when you cancel the execution job. 
Therefore, you might see some updated documents, while other documents have no or stale results from a previous
execution.

### Pregel Algorithms

#### PageRank

#### Single-Source Shortest Path

#### Connected Components

#### Hyperlink-Induced Topic Search (HITS)

#### Vertex Centrality

#### Community Detection


Free Datasets
-------------

* [Stanford Network Analysis Project](http://snap.stanford.edu/data/soc-pokec.html)