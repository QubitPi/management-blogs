---
layout: post
title: Deploy Hadoop Cluster
tags: [Hadoop]
color: rgb(250, 154, 133)
feature-img: "assets/img/pexels/design-art/2020-08-16-25-jersey-cdi-container-agnostic-support/cover.png"
thumbnail: "assets/img/pexels/design-art/2020-08-16-25-jersey-cdi-container-agnostic-support/cover.png"
author: QubitPi
excerpt_separator: <!--more-->
---

<!--more-->

* TOC
{:toc} 

We will deploy a 3-node Hadoop cluster using 3 VM's whose info is given below.

| # |  Username | Hostname | IP Address   |
|:-:|:---------:|----------|--------------|
| 1 | openstack | node1    | 192.168.99.2 |
| 2 | openstack | node2    | 192.168.99.3 |
| 3 | openstack | node3    | 192.168.99.4 |

We will have node1 as NameNode and the rest as DataNodes.

### Configure VM

    sudo apt-get update
    sudo apt-get upgrade
    sudo apt update
    sudo apt upgrade
    
    sudo apt-get install openjdk-8-jdk --yes
    
### Configure DNS Lookup

Add the following to `/etc/hosts`

    192.168.99.2 node1
    192.168.99.3 node2
    192.168.99.4 node3
    
Comment out the line containing
[non-permanent IP](https://www.debian.org/doc/manuals/debian-reference/ch05.en.html#_the_hostname_resolution) in each
node:

    # 127.0.1.1 node1
    # 127.0.1.1 node2
    # 127.0.1.1 node3
    
otherwise, DataNode will not be able to connect NameNode later

### Setup Passwordless SSH

#### Generate SSH Key in Each Host

    ssh-keygen -t rsa
    
#### Copy SSH key

In each host, run the following commands

    ssh-copy-id openstack@node1
    ssh-copy-id openstack@node2
    ssh-copy-id openstack@node3
    
### Download and Install

Take version 2.8.1 as an example, unextract hadoop-2.8.1.tar.gz and put it under `~`, which will be our `$HADOOP_HOME`.
    
### Edit Config File

#### NameNode

##### `$HADOOP_HOME/etc/hadoop/slaves`:

    node2
    node3
    
#### DataNodes

##### `$HADOOP_HOME/etc/hadoop/yarn-site.xml`:

```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>node1:8031</value>
    </property>
</configuration>
```

#### All Nodes(NameNode + DataNodes)

##### `$HADOOP_HOME/etc/hadoop/core-site.xml`

```xml
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://node1:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/tmp/hadoop</value>
    </property>
</configuration>
```

##### `$HADOOP_HOME/etc/hadoop/mapred-site.xml`

```xml
<configuration>
    <property>
        <name>mapred.job.tracker</name>
        <value>node1:9001</value>
    </property>
</configuration>
```

##### `$HADOOP_HOME/etc/hadoop/hdfs-site.xml`

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>
</configuration>
```

##### `$HADOOP_HOME/etc/hadoop/hadoop-env.sh`

```bash
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
```

##### `~/.bashrc`

```
# hadoop
export HADOOP_HOME=~/hadoop-2.8.1
export JAVA_HOME=Java-home
export PATH=$PATH:~/hadoop-2.8.1/bin/

export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
```